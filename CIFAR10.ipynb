{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Dataset\n",
    "\n",
    "The dataset used in this notebook is downloaded from [here](https://www.cs.toronto.edu/~kriz/cifar.html). CIFAR-10 dataset is a subset of 80 million tiny image dataset. CIFAR-10 consists of 60,000 images in total. Training data has around 50k images and the test data has 10k images. CIFAR-10 dataset has 10 categories with 6000 images in each category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages\n",
    "\n",
    "In this notebook, we will be mainly working with PyTorch for building and training ConvNets on CIFAR10 Dataset. Using PyTorch makes things more easier to understand however, whatever we do here must be similar in TensorFlow as well. \n",
    "\n",
    "*Note : The python scripts for this notebook will be slightly different from this notebook. But all the concepts used will be the same. Also please move this notebook to main project directory.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.transforms import ToTensor,Compose,RandomHorizontalFlip, Normalize, ToPILImage, RandomRotation, ColorJitter\n",
    "from torchvision.utils import make_grid\n",
    "import mcbe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the downloaded dataset\n",
    "\n",
    "The dataset downloaded has 6 batches, `data_batch1, data_batch2,..., data_batch5` are the training batches. Each batch has 10k images in it. `test_batch` is the batch that is meant to be used for model testing. The test batch contains 10k images.\n",
    "\n",
    "The batches has been created using cPickle. Each batch is an array of shape (10000,3072) where 10,000 is number of images and 3072 is the pixel values of the image.\n",
    "\n",
    "Extracting the dataset according to the method suggested in the [CIFAR-10 Website](https://www.cs.toronto.edu/~kriz/cifar.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(filename):\n",
    "    with open(filename,\"rb\") as f:\n",
    "        batch_data = pickle.load(f,encoding=\"bytes\")\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [] #Store all batches in a list\n",
    "for files in os.listdir(\"cifar-10-batches-py\"):\n",
    "    if \"_batch\" in files:\n",
    "        data.append(extract(os.path.join('./cifar-10-batches-py',files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Custom Dataset Class using `Dataset` Module\n",
    "\n",
    "Using the above method to extarct, we will now create a custom dataset class which inherits the `Dataset` class from `torch.utils.data` package. Creating this custom dataset class is essential as it will help us easily manage our dataset and apply the data augmentation during runtime. The `DataLoader` package takes full advantage of this custom dataset class. Instead of loading all the images at once, the `DataLoader` reads batches of data. Even though we already have batches of data in our dataset, creating this custom class allows us to use any batch_size. Currently, the batches_data have 10k images in them. Having so many images in one batch may not fit in memory. Hence to change this batch_size, we will create a custom dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10(Dataset):\n",
    "    \n",
    "    def __init__(self,root,train=True,transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.split = train\n",
    "        \n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "        self.train_data = [file for file in os.listdir(root) if \"data_batch\" in file]\n",
    "        self.test_data = [file for file in os.listdir(root) if \"test_batch\" in file]\n",
    "                \n",
    "        data_split = self.train_data if self.split else self.test_data\n",
    "        \n",
    "        for files in data_split:\n",
    "            entry = self.extract(os.path.join(root,files))\n",
    "            self.data.append(entry[\"data\"])\n",
    "            self.targets.extend(entry[\"labels\"])\n",
    "                \n",
    "        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n",
    "        self.data = self.data.transpose((0, 2, 3, 1))\n",
    "        self.load_meta()\n",
    "        \n",
    "    def extract(self,filename):\n",
    "        with open(filename,\"rb\") as f:\n",
    "            batch_data = pickle.load(f,encoding=\"latin1\")\n",
    "        return batch_data  \n",
    "    \n",
    "    def load_meta(self):\n",
    "        path = os.path.join(self.root,\"batches.meta\")\n",
    "        with open(path,\"rb\") as infile:\n",
    "            data = pickle.load(infile,encoding=\"latin1\")\n",
    "            self.classes = data[\"label_names\"]\n",
    "            self.classes_to_idx = {_class:i for i,_class in enumerate(self.classes)}\n",
    "            \n",
    "    def plot(self,image,target=None):\n",
    "        if target is not None:\n",
    "            print(f\"Target :{target} class :{self.classes[target]}\")\n",
    "        plt.figure(figsize=(2,2))\n",
    "        plt.imshow(image.permute(1,2,0))\n",
    "        plt.show()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image,target = self.data[idx],self.targets[idx]\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "            \n",
    "        return image,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CIFAR10(root=\"./cifar-10-batches-py\",train=True,\n",
    "                    transforms=Compose([\n",
    "                        ToTensor()]))\n",
    "test_set = CIFAR10(root=\"./cifar-10-batches-py\",train=False,\n",
    "                    transforms=Compose([\n",
    "                        ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch = train_set[1036]\n",
    "#img,label = batch\n",
    "#train_set.plot(img,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building ConvNet Model\n",
    "\n",
    "Now that we are done with constructing the dataset class, it's time to build a ConvNet model. We will also create a class which specifies the training configurations so that it becomes easier for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Maxbias_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,max_bias, bias):\n",
    "        return 0.01*np.linalg.norm(np.max(np.array([bias - max_bias, np.zeros_like(bias)]),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=8,stride=1,kernel_size=(3,3),padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8,out_channels=32,kernel_size=(3,3),padding=1,stride=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=(3,3),padding=1,stride=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=(3,3),padding=1,stride=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=128,out_channels=256,kernel_size=(3,3),stride=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=6*6*256,out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=256,out_features=512)\n",
    "        self.fc3 = nn.Linear(in_features=512,out_features=128)\n",
    "        self.fc4 = nn.Linear(in_features=128,out_features=64)\n",
    "        self.fc5 = nn.Linear(in_features=64,out_features=10)\n",
    "        \n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=(2,2),stride=2)\n",
    "        self.dropout = nn.Dropout2d(p=0.5)\n",
    "        \n",
    "    def forward(self,x,targets,inj=True):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1,6*6*256)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        mcbe_train = x.detach().numpy()\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        logits = self.fc5(x)\n",
    "        \n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            if not inj:\n",
    "                loss = F.cross_entropy(logits,targets)\n",
    "            else:\n",
    "                loss1 = F.cross_entropy(logits,targets)\n",
    "                max_bias = mcbe.dd_mcbe(W=np.array(self.fc2.weight.detach().numpy()),X_train = mcbe_train, num_estimation_points=1000,dd_method=\"blowup\")\n",
    "                loss_fn_maxbias = Maxbias_loss()\n",
    "                loss2 = loss_fn_maxbias(max_bias,self.fc2.bias.detach().numpy())\n",
    "                loss = loss1 + loss2\n",
    "                #print(\"crossentropy:\",loss1,\"maxbias:\",loss2)\n",
    "        return logits,loss\n",
    "    \n",
    "    def configure_optimizers(self,config):\n",
    "        optimizer = optim.Adam(self.parameters(),lr=config.lr,betas=config.betas,weight_decay=config.weight_decay)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=9216, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc5): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (max_pool): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout2d(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Training Configuration Class\n",
    "\n",
    "I often see people just specify the training configurations directly. I don't prefer this way. We will create a simple training config class and pass that config class when we train our model. This makes it a neat way of training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingConfig:\n",
    "    \n",
    "    lr=3e-4\n",
    "    betas=(0.9,0.995)\n",
    "    weight_decay=5e-4\n",
    "    num_workers=0\n",
    "    max_epochs=10\n",
    "    batch_size=64\n",
    "    ckpt_path=None #Specify a model path here. Ex: \"./Model.pt\"\n",
    "    shuffle=True\n",
    "    pin_memory=True\n",
    "    verbose=True\n",
    "    \n",
    "    def __init__(self,**kwargs):\n",
    "        for key,value in kwargs.items():\n",
    "            setattr(self,key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Training Loop\n",
    "\n",
    "Now, we will be creating a simple training loop to train our model. It may look complicated but trust me, when you understand what is going on, it's simple. It also shows how other libraries like TensorFlow will hide some important stuff from you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self,model,train_dataset,test_dataset,config):\n",
    "        self.model = model\n",
    "        self.train_dataset=train_dataset\n",
    "        self.test_dataset=test_dataset\n",
    "        self.config = config\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.test_losses = []\n",
    "        self.test_accuracies = []\n",
    "        \n",
    "        self.device = \"cpu\"\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.cuda.current_device()\n",
    "            self.model = self.model.to(self.device)\n",
    "    \n",
    "    def save_checkpoint(self):\n",
    "        raw_model = self.model.module if hasattr(self.model,\"module\") else self.model\n",
    "        torch.save(raw_model.state_dict(),self.config.ckpt_path)\n",
    "        print(\"Model Saved!\")\n",
    "        \n",
    "    def train(self):\n",
    "        model,config = self.model,self.config\n",
    "        raw_model = self.model.module if hasattr(self.model,\"module\") else self.model\n",
    "        optimizer = raw_model.configure_optimizers(config)\n",
    "        \n",
    "        def run_epoch(split):\n",
    "            is_train = split==\"train\"\n",
    "            if is_train:\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval() #important don't miss this. Since we have used dropout, this is required.\n",
    "            data = self.train_dataset if is_train else self.test_dataset\n",
    "            loader = DataLoader(data,batch_size=config.batch_size,\n",
    "                                shuffle=config.shuffle,\n",
    "                                pin_memory=config.pin_memory,\n",
    "                                num_workers=config.num_workers)\n",
    "            \n",
    "            losses = []\n",
    "            accuracies = []\n",
    "            correct = 0\n",
    "            num_samples = 0\n",
    "            \n",
    "            pbar = tqdm(enumerate(loader),total=len(loader)) if is_train and config.verbose else enumerate(loader)\n",
    "            for it,(images,targets) in pbar:\n",
    "                images = images.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "                num_samples += targets.size(0)\n",
    "                \n",
    "                with torch.set_grad_enabled(is_train):\n",
    "                    #forward the model\n",
    "                    logits,loss = model(images,targets)\n",
    "                    loss = loss.mean()\n",
    "                    losses.append(loss.item())\n",
    "                    \n",
    "                with torch.no_grad():\n",
    "                    predictions = torch.argmax(logits,dim=1) #softmax gives prob distribution. Find the index of max prob\n",
    "                    correct+= predictions.eq(targets).sum().item()\n",
    "                    accuracies.append(correct/num_samples)\n",
    "                    \n",
    "                if is_train:\n",
    "                    model.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    if config.verbose:\n",
    "                        pbar.set_description(f\"Epoch:{epoch+1} iteration:{it+1} | loss:{np.mean(losses)} accuracy:{np.mean(accuracies)} lr:{config.lr}\")\n",
    "                    \n",
    "                    self.train_losses.append(np.mean(losses))\n",
    "                    self.train_accuracies.append(np.mean(accuracies))\n",
    "            \n",
    "            if not is_train:\n",
    "                test_loss = np.mean(losses)\n",
    "                if config.verbose:\n",
    "                    print(f\"\\nEpoch:{epoch+1} | Test Loss:{test_loss} Test Accuracy:{correct/num_samples}\\n\")\n",
    "                self.test_losses.append(test_loss)\n",
    "                self.test_accuracies.append(correct/num_samples)\n",
    "                return test_loss\n",
    "                \n",
    "        best_loss = float('inf')\n",
    "        test_loss = float('inf')\n",
    "        \n",
    "        for epoch in range(config.max_epochs):\n",
    "            run_epoch('train')\n",
    "            if self.test_dataset is not None:\n",
    "                test_loss = run_epoch(\"test\")\n",
    "                \n",
    "            good_model = self.test_dataset is not None and test_loss < best_loss\n",
    "            if config.ckpt_path is not None and good_model:\n",
    "                best_loss = test_loss\n",
    "                self.save_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dumb Baselines\n",
    "\n",
    "In this section we will get a dumb baseline score which we can use to compare our model against. To get dumb baseline scores, we will pass a zero input image and ask our model to predict something. By doing this, we can see whether our model has learnt to extract any information from the images at all when we pass an actual image from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of mcbe_train (10, 256)\n",
      "[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 8.2395039e-05\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 7.5554568e-04 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.0131067e-03\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 3.1760908e-03\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 6.7241527e-03\n",
      "  1.0395077e-02 3.3263308e-03]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.         0.         ... 0.         0.00833551 0.00201727]\n",
      " [0.00024182 0.00019778 0.         ... 0.         0.02338493 0.02496902]\n",
      " [0.         0.         0.         ... 0.         0.03543283 0.02755793]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.03616854 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.00135667 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.01564854 0.03104077]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.         0.         ... 0.         0.01421448 0.01305059]\n",
      " [0.         0.         0.         ... 0.         0.01277984 0.01791276]\n",
      " [0.         0.         0.         ... 0.         0.         0.02961308]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.03066025 0.02551233]\n",
      " [0.         0.         0.         ... 0.         0.00789001 0.03425494]\n",
      " [0.         0.         0.         ... 0.         0.01426847 0.02488703]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.         0.         ... 0.         0.01139475 0.04345314]\n",
      " [0.         0.         0.         ... 0.         0.         0.01413878]\n",
      " [0.00233724 0.         0.         ... 0.         0.0411012  0.0820761 ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.0129859  0.03095395]\n",
      " [0.         0.         0.         ... 0.         0.         0.03429554]\n",
      " [0.         0.         0.         ... 0.         0.01808116 0.03349169]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.         0.         ... 0.         0.03777281 0.08082843]\n",
      " [0.         0.         0.         ... 0.         0.02503734 0.02348417]\n",
      " [0.         0.         0.         ... 0.         0.04740495 0.06186741]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.03061146 0.06780387]\n",
      " [0.         0.         0.         ... 0.         0.00176884 0.04406197]\n",
      " [0.         0.         0.         ... 0.         0.04597328 0.07904468]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.         0.01486289 ... 0.         0.05522357 0.06269549]\n",
      " [0.         0.         0.01119735 ... 0.         0.         0.04348709]\n",
      " [0.         0.         0.         ... 0.         0.07832817 0.07341768]\n",
      " ...\n",
      " [0.         0.         0.0006905  ... 0.         0.0131435  0.0557113 ]\n",
      " [0.         0.         0.         ... 0.         0.02889173 0.03187373]\n",
      " [0.         0.         0.         ... 0.         0.01508427 0.07085504]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.         0.         ... 0.         0.03873359 0.0335171 ]\n",
      " [0.         0.         0.         ... 0.         0.04340476 0.09844273]\n",
      " [0.         0.         0.         ... 0.         0.00371516 0.07825464]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.09669954 0.17541811]\n",
      " [0.         0.0214753  0.         ... 0.         0.03794799 0.11056895]\n",
      " [0.         0.         0.         ... 0.         0.02725384 0.06962084]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.         0.03679219 ... 0.         0.05516545 0.10384987]\n",
      " [0.         0.         0.01017792 ... 0.         0.07404068 0.08932146]\n",
      " [0.         0.         0.         ... 0.         0.03335849 0.1446898 ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.12290649]\n",
      " [0.         0.         0.         ... 0.         0.05525306 0.11206355]\n",
      " [0.         0.         0.0416564  ... 0.         0.08349185 0.09071736]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.         0.00066278 ... 0.         0.11517213 0.19775072]\n",
      " [0.         0.         0.02593521 ... 0.         0.01528658 0.1347791 ]\n",
      " [0.         0.         0.         ... 0.         0.12848718 0.21517426]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.01579866 0.10928912]\n",
      " [0.         0.         0.         ... 0.         0.05813111 0.09668067]\n",
      " [0.         0.01088044 0.01315118 ... 0.         0.09955363 0.20351723]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.         0.06811326 ... 0.         0.0532884  0.18973517]\n",
      " [0.         0.         0.03089018 ... 0.         0.09918164 0.15088212]\n",
      " [0.         0.         0.09730072 ... 0.         0.04692289 0.20010436]\n",
      " ...\n",
      " [0.         0.         0.00099356 ... 0.         0.18902011 0.29667926]\n",
      " [0.         0.02737264 0.04125344 ... 0.         0.04423617 0.2545532 ]\n",
      " [0.         0.         0.05491637 ... 0.         0.12348977 0.16672179]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.         0.00171847 ... 0.         0.11547092 0.34849378]\n",
      " [0.         0.         0.14685012 ... 0.         0.1699157  0.4454292 ]\n",
      " [0.         0.         0.04216197 ... 0.         0.18790072 0.34242398]\n",
      " ...\n",
      " [0.         0.         0.10655411 ... 0.         0.0448699  0.23284999]\n",
      " [0.         0.044938   0.04939007 ... 0.         0.07059287 0.26869702]\n",
      " [0.         0.         0.15058963 ... 0.         0.09259203 0.36540145]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.01118203 0.17487818 ... 0.         0.22451162 0.39614037]\n",
      " [0.         0.05671081 0.19780418 ... 0.         0.10406926 0.48234123]\n",
      " [0.         0.         0.2331767  ... 0.         0.03624717 0.39897794]\n",
      " ...\n",
      " [0.         0.         0.13640408 ... 0.         0.         0.293038  ]\n",
      " [0.         0.0141249  0.132811   ... 0.         0.15541065 0.47633687]\n",
      " [0.         0.07825985 0.12509163 ... 0.         0.06970717 0.43325   ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.0356355  0.21503429 ... 0.         0.15016504 0.6595444 ]\n",
      " [0.         0.04486553 0.29271686 ... 0.         0.08322746 0.5192466 ]\n",
      " [0.         0.         0.280785   ... 0.         0.         0.41507974]\n",
      " ...\n",
      " [0.         0.08200297 0.26360962 ... 0.         0.03322468 0.40645686]\n",
      " [0.         0.04063787 0.10944099 ... 0.         0.06664225 0.46292794]\n",
      " [0.         0.         0.16295423 ... 0.         0.3148542  0.47040623]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.19522269 0.23427248 ... 0.         0.09529433 0.58545935]\n",
      " [0.         0.17434469 0.33248216 ... 0.         0.2702216  0.8768569 ]\n",
      " [0.         0.22400862 0.1343309  ... 0.         0.20101799 0.7207974 ]\n",
      " ...\n",
      " [0.         0.02468038 0.32968956 ... 0.         0.13075188 0.7852713 ]\n",
      " [0.         0.11466883 0.37066558 ... 0.         0.09018269 0.7963626 ]\n",
      " [0.         0.1348311  0.19841382 ... 0.         0.1011655  0.5142284 ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.07688889 0.34912407 ... 0.         0.06442231 0.7578293 ]\n",
      " [0.         0.08131958 0.41016287 ... 0.         0.2173588  0.66420925]\n",
      " [0.         0.10602692 0.4289047  ... 0.         0.16796988 0.7461953 ]\n",
      " ...\n",
      " [0.         0.04927768 0.4959145  ... 0.         0.06821945 0.79935026]\n",
      " [0.         0.07917488 0.63661003 ... 0.         0.         0.6106943 ]\n",
      " [0.         0.3368253  0.4090394  ... 0.         0.00473842 0.5676869 ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.24324335 0.9039922  ... 0.         0.29545626 1.1920019 ]\n",
      " [0.         0.3016749  0.58964837 ... 0.         0.14614534 0.8800639 ]\n",
      " [0.         0.49249703 0.69248354 ... 0.         0.         1.2239823 ]\n",
      " ...\n",
      " [0.         0.1956755  1.0407884  ... 0.         0.14665762 1.0837624 ]\n",
      " [0.         0.2880053  0.6345476  ... 0.         0.028041   0.81984746]\n",
      " [0.         0.37349743 1.0019691  ... 0.         0.307108   1.4382548 ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.46424145 1.611573   ... 0.         0.35613045 1.3635325 ]\n",
      " [0.         0.5194466  0.7222178  ... 0.         0.21320212 1.2112523 ]\n",
      " [0.         0.6402222  1.4230863  ... 0.         0.15916081 2.045322  ]\n",
      " ...\n",
      " [0.         0.5483715  0.8756357  ... 0.         0.42584187 1.1876427 ]\n",
      " [0.         0.31985718 0.9147529  ... 0.         0.         1.057627  ]\n",
      " [0.         0.34281737 0.6339437  ... 0.         0.300851   1.0469668 ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.12731084 0.82522416 ... 0.         0.04528943 1.3318659 ]\n",
      " [0.         0.4217183  1.0338874  ... 0.         0.11003118 1.1309705 ]\n",
      " [0.         0.8223852  1.8555965  ... 0.         0.339328   2.1572578 ]\n",
      " ...\n",
      " [0.         0.6668394  1.3565493  ... 0.         0.19094408 1.337614  ]\n",
      " [0.         0.23775901 1.3305738  ... 0.         0.129177   1.4273282 ]\n",
      " [0.         0.21795091 0.94159997 ... 0.         0.07995723 1.1115137 ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.36911976 1.1815352  ... 0.         0.         1.2571311 ]\n",
      " [0.         0.5600884  2.0253263  ... 0.         0.         1.8024231 ]\n",
      " [0.         0.56559724 1.5067496  ... 0.         0.10127807 2.0103958 ]\n",
      " ...\n",
      " [0.         0.88716984 1.2110324  ... 0.         0.14337441 1.5180774 ]\n",
      " [0.         0.6084825  1.6290878  ... 0.         0.05460423 1.7334732 ]\n",
      " [0.         0.6941844  1.7013254  ... 0.         0.16412479 1.830028  ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.55575395 1.8100283  ... 0.         0.         1.4859781 ]\n",
      " [0.         0.57573926 2.0367455  ... 0.         0.03951833 1.6364428 ]\n",
      " [0.         0.6677582  1.8455474  ... 0.         0.0447467  1.4947417 ]\n",
      " ...\n",
      " [0.         0.34751785 1.4756019  ... 0.         0.         1.5357516 ]\n",
      " [0.         0.61921287 1.7909946  ... 0.         0.10018212 1.6547487 ]\n",
      " [0.         1.0343019  1.9502804  ... 0.         0.         1.3129264 ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.0000000e+00 5.8240104e-01 2.1997333e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 9.4837582e-01]\n",
      " [0.0000000e+00 7.0364100e-01 1.7419417e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.1823477e+00]\n",
      " [0.0000000e+00 7.0190060e-01 1.7474382e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.5805039e+00]\n",
      " ...\n",
      " [0.0000000e+00 7.3732865e-01 1.9877515e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.2259265e+00]\n",
      " [0.0000000e+00 2.2141165e-01 1.7766309e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 1.2587798e+00]\n",
      " [0.0000000e+00 7.6274574e-04 2.1095457e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 7.7915311e-01]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.7485056  2.5501273  ... 0.         0.         1.4621185 ]\n",
      " [0.         0.5992468  2.34883    ... 0.         0.         0.91122264]\n",
      " [0.         0.5847509  2.2747095  ... 0.         0.         1.7834481 ]\n",
      " ...\n",
      " [0.         0.5614892  1.9884079  ... 0.         0.         1.2306397 ]\n",
      " [0.         0.54182744 1.3259482  ... 0.         0.         0.9138497 ]\n",
      " [0.         0.50159085 1.9263128  ... 0.         0.         0.90398055]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.52717876 2.2545626  ... 0.         0.         1.1617985 ]\n",
      " [0.         1.0110273  2.9005857  ... 0.         0.         1.605014  ]\n",
      " [0.         0.47931644 2.1090753  ... 0.         0.         1.1898639 ]\n",
      " ...\n",
      " [0.         0.64470685 2.354221   ... 0.         0.         0.73323333]\n",
      " [0.         1.1152068  3.3928971  ... 0.         0.         1.4207158 ]\n",
      " [0.         0.17502189 1.6897662  ... 0.         0.         0.35529208]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.22935997 2.046979   ... 0.         0.         0.66964513]\n",
      " [0.         0.48646876 2.6622705  ... 0.         0.         0.9011886 ]\n",
      " [0.         0.48835704 2.2391787  ... 0.         0.         1.0153271 ]\n",
      " ...\n",
      " [0.         0.9316378  1.7795677  ... 0.         0.         0.92941284]\n",
      " [0.         0.59579325 2.3599572  ... 0.         0.         0.6879542 ]\n",
      " [0.         0.7936038  1.9558465  ... 0.         0.         0.748999  ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.5971206  2.8880365  ... 0.         0.         0.9571661 ]\n",
      " [0.         0.760287   2.1783621  ... 0.         0.         0.7404068 ]\n",
      " [0.         1.0278418  2.426402   ... 0.         0.         0.8756174 ]\n",
      " ...\n",
      " [0.         0.684162   1.7469149  ... 0.         0.         0.24743241]\n",
      " [0.         0.86603737 2.436865   ... 0.         0.         0.67821264]\n",
      " [0.         0.7660341  2.02274    ... 0.         0.         0.38301498]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.7043258  2.796348   ... 0.         0.         1.0183907 ]\n",
      " [0.         0.48871517 2.0275524  ... 0.         0.         0.5626185 ]\n",
      " [0.         0.15461454 2.2598643  ... 0.         0.         0.6448314 ]\n",
      " ...\n",
      " [0.         1.1459672  3.0939894  ... 0.         0.         0.6009077 ]\n",
      " [0.         1.0366806  3.0859008  ... 0.         0.         0.3706064 ]\n",
      " [0.         0.4379499  2.509925   ... 0.         0.         0.61007273]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.8732125  3.959885   ... 0.         0.         0.5567862 ]\n",
      " [0.         0.8721905  2.409927   ... 0.         0.         0.27941132]\n",
      " [0.         1.3600482  4.634006   ... 0.         0.         1.0269293 ]\n",
      " ...\n",
      " [0.         0.921569   1.9722031  ... 0.         0.         0.28027833]\n",
      " [0.         0.60521114 2.825022   ... 0.         0.         0.40939617]\n",
      " [0.         0.3512027  2.1507807  ... 0.         0.         0.36074102]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.65936935 2.7705283  ... 0.         0.         0.17897695]\n",
      " [0.         0.58082855 2.534568   ... 0.         0.         0.2688666 ]\n",
      " [0.         0.6867305  3.9491227  ... 0.         0.         0.23405334]\n",
      " ...\n",
      " [0.         1.0995169  3.218789   ... 0.         0.         0.6546731 ]\n",
      " [0.         1.065344   2.9556258  ... 0.         0.         0.40451998]\n",
      " [0.         1.3524678  2.9726853  ... 0.         0.         0.17702833]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.76539034 2.7932549  ... 0.         0.         0.13069199]\n",
      " [0.         0.46379283 3.0723162  ... 0.         0.         0.37577432]\n",
      " [0.         0.63269323 1.8068252  ... 0.         0.         0.15911204]\n",
      " ...\n",
      " [0.         0.62313956 3.6704838  ... 0.         0.         0.3112197 ]\n",
      " [0.         1.4314992  3.0030093  ... 0.         0.         0.        ]\n",
      " [0.         0.5574959  2.6249878  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.26945418 3.2829087  ... 0.         0.         0.6466603 ]\n",
      " [0.         1.1310204  2.5078073  ... 0.         0.         0.303486  ]\n",
      " [0.         0.8525785  2.618203   ... 0.         0.         0.49749905]\n",
      " ...\n",
      " [0.         0.558486   4.075602   ... 0.         0.         0.12234029]\n",
      " [0.         1.1775889  3.3207242  ... 0.         0.         0.65447724]\n",
      " [0.         0.3696915  3.2737954  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.4543765  4.897888   ... 0.         0.         0.        ]\n",
      " [0.         0.26147825 2.2867653  ... 0.         0.         0.        ]\n",
      " [0.         0.704198   3.6107514  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.54040694 3.5408127  ... 0.         0.         0.18477032]\n",
      " [0.         0.32074052 3.8645372  ... 0.         0.         0.        ]\n",
      " [0.         0.4699389  2.021259   ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.         3.484808   ... 0.         0.         0.        ]\n",
      " [0.         0.36759886 4.1960893  ... 0.         0.         0.        ]\n",
      " [0.         0.10490675 3.3527944  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         1.057189   3.3276472  ... 0.         0.         0.        ]\n",
      " [0.         0.5690994  3.4745693  ... 0.         0.         0.        ]\n",
      " [0.         0.04561305 2.9307723  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         1.1135379  4.3217063  ... 0.         0.         0.        ]\n",
      " [0.         0.23180684 2.8093815  ... 0.         0.         0.        ]\n",
      " [0.         1.0358623  3.6787903  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         1.2010605  4.705003   ... 0.         0.         0.        ]\n",
      " [0.         0.4879936  3.7415807  ... 0.         0.         0.        ]\n",
      " [0.         0.04605285 2.9088154  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.         4.341963   ... 0.         0.         0.        ]\n",
      " [0.         0.47591698 4.242926   ... 0.         0.         0.        ]\n",
      " [0.         0.4401398  5.3362722  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.5239868  2.6889405  ... 0.         0.         0.        ]\n",
      " [0.         0.47598207 4.490238   ... 0.         0.         0.        ]\n",
      " [0.         0.36837146 3.9162643  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.89316994 4.9218845  ... 0.         0.         0.        ]\n",
      " [0.         0.         6.2441697  ... 0.         0.         0.        ]\n",
      " [0.         0.7766551  4.250337   ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         1.0555769  2.8469281  ... 0.         0.         0.        ]\n",
      " [0.         0.83306205 4.776563   ... 0.         0.         0.        ]\n",
      " [0.         0.         4.288596   ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.61952    3.7445178  ... 0.         0.         0.        ]\n",
      " [0.         0.80974996 4.409153   ... 0.         0.         0.        ]\n",
      " [0.         0.29874405 5.0097523  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.915412   3.4634466  ... 0.         0.         0.        ]\n",
      " [0.         0.         4.3558145  ... 0.         0.         0.        ]\n",
      " [0.         1.2947129  4.194854   ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         1.0107944  3.230483   ... 0.         0.         0.06295583]\n",
      " [0.         1.0195873  4.0969114  ... 0.         0.         0.        ]\n",
      " [0.         1.7360218  5.5773807  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.37209204 4.8059587  ... 0.         0.         0.        ]\n",
      " [0.         0.6713173  4.0003095  ... 0.         0.         0.        ]\n",
      " [0.         0.71318746 3.645405   ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.40680546 3.3338194  ... 0.         0.         0.        ]\n",
      " [0.         0.3605472  3.669307   ... 0.         0.         0.        ]\n",
      " [0.         0.78583276 4.81456    ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.3103123  4.0222964  ... 0.         0.         0.        ]\n",
      " [0.         0.31035638 3.9448934  ... 0.         0.         0.        ]\n",
      " [0.         1.119093   5.341351   ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.04664514 4.1724143  ... 0.         0.         0.        ]\n",
      " [0.         0.58647865 4.954253   ... 0.         0.         0.        ]\n",
      " [0.         0.         3.317836   ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.927797   4.5371737  ... 0.         0.         0.        ]\n",
      " [0.         0.46171308 4.2137623  ... 0.         0.         0.        ]\n",
      " [0.         0.722219   3.5658746  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.6694655  3.70258    ... 0.         0.         0.        ]\n",
      " [0.         0.14972924 3.6983993  ... 0.         0.         0.        ]\n",
      " [0.         0.87284863 3.5412579  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.95742023 4.012946   ... 0.         0.         0.        ]\n",
      " [0.         0.13093936 3.2142768  ... 0.         0.         0.        ]\n",
      " [0.         0.8935708  2.6383474  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.5402233  4.7660265  ... 0.         0.         0.        ]\n",
      " [0.         0.         4.975609   ... 0.         0.         0.        ]\n",
      " [0.         0.5832991  6.1157885  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.28516686 2.7250643  ... 0.         0.         0.        ]\n",
      " [0.         0.66764396 3.6352918  ... 0.         0.         0.        ]\n",
      " [0.         1.1274374  4.752129   ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.509709   4.053541   ... 0.         0.         0.        ]\n",
      " [0.         0.02427706 4.88257    ... 0.         0.         0.        ]\n",
      " [0.         1.702295   5.076964   ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         1.5097536  5.3004084  ... 0.         0.         0.        ]\n",
      " [0.         0.6707194  4.226943   ... 0.         0.         0.        ]\n",
      " [0.         0.45988023 3.041763   ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.45380166 3.8900864  ... 0.         0.         0.        ]\n",
      " [0.         0.41794503 2.535799   ... 0.         0.         0.        ]\n",
      " [0.         0.18065369 4.8760614  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.11224771 3.1445055  ... 0.         0.         0.        ]\n",
      " [0.         1.1328676  3.7303355  ... 0.         0.         0.        ]\n",
      " [0.         1.423252   5.5993886  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         1.4316595  5.3000603  ... 0.         0.         0.        ]\n",
      " [0.         0.46459797 3.8506584  ... 0.         0.         0.        ]\n",
      " [0.         0.5306445  4.2116857  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.659271   4.2340236  ... 0.         0.         0.        ]\n",
      " [0.         0.5451169  4.163394   ... 0.         0.         0.        ]\n",
      " [0.         0.7605258  3.9550416  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.75835633 2.8961468  ... 0.         0.         0.        ]\n",
      " [0.         1.2979765  5.506414   ... 0.         0.         0.        ]\n",
      " [0.         0.24000615 6.3945436  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.6615878  4.8681717  ... 0.         0.         0.        ]\n",
      " [0.         0.63825846 4.069712   ... 0.         0.         0.        ]\n",
      " [0.         0.         5.0898075  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.         5.0898647  ... 0.         0.         0.        ]\n",
      " [0.         0.2711755  5.008942   ... 0.         0.         0.        ]\n",
      " [0.         1.1170707  4.0177526  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         3.868868   ... 0.         0.         0.        ]\n",
      " [0.         1.2994958  2.9588418  ... 0.         0.         0.        ]\n",
      " [0.         0.39287567 4.050509   ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        0.7475842 6.6157775 ... 0.        0.        0.       ]\n",
      " [0.        0.0367489 3.1407688 ... 0.        0.        0.       ]\n",
      " [0.        0.2655455 3.1367483 ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        1.0058479 3.3519678 ... 0.        0.        0.       ]\n",
      " [0.        0.6406041 3.4538918 ... 0.        0.        0.       ]\n",
      " [0.        1.0510035 5.3530116 ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.0775173  3.8169713  ... 0.         0.         0.        ]\n",
      " [0.         0.         2.8983576  ... 0.         0.         0.        ]\n",
      " [0.         1.7749187  6.211548   ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.81484914 4.9688883  ... 0.         0.         0.        ]\n",
      " [0.         0.19466126 3.731812   ... 0.         0.         0.        ]\n",
      " [0.         0.         4.611841   ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         1.1322936  3.9044514  ... 0.         0.         0.        ]\n",
      " [0.         1.4198503  4.474568   ... 0.         0.         0.        ]\n",
      " [0.         0.86499196 3.050242   ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         1.0364685  4.079401   ... 0.         0.         0.        ]\n",
      " [0.         1.0116392  3.973473   ... 0.         0.         0.        ]\n",
      " [0.         1.8539412  4.281593   ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        0.        6.869944  ... 0.        0.        0.       ]\n",
      " [0.        1.1017923 4.014935  ... 0.        0.        0.       ]\n",
      " [0.        1.9005506 5.5742836 ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        1.0161288 6.582418  ... 0.        0.        0.       ]\n",
      " [0.        0.7609235 3.7919211 ... 0.        0.        0.       ]\n",
      " [0.        0.4650564 3.7576604 ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        1.3935735 4.366792  ... 0.        0.        0.       ]\n",
      " [0.        0.6468954 3.500389  ... 0.        0.        0.       ]\n",
      " [0.        1.4698161 4.3074694 ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        0.272977  5.6337223 ... 0.        0.        0.       ]\n",
      " [0.        1.1267444 4.181633  ... 0.        0.        0.       ]\n",
      " [0.        0.5517714 3.5987575 ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.6698776  5.3649397  ... 0.         0.         0.        ]\n",
      " [0.         0.6561441  2.8220553  ... 0.         0.         0.        ]\n",
      " [0.         1.2747513  5.6759586  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         1.0899378  5.9174333  ... 0.         0.         0.        ]\n",
      " [0.         1.6447768  5.404869   ... 0.         0.         0.        ]\n",
      " [0.         0.19662893 5.3775115  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.5063554  2.5450401  ... 0.         0.         0.        ]\n",
      " [0.         2.381718   7.7705874  ... 0.         0.         0.        ]\n",
      " [0.         1.0898046  5.0764327  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.3916139  5.0392966  ... 0.         0.         0.        ]\n",
      " [0.         0.98342836 5.243417   ... 0.         0.         0.        ]\n",
      " [0.         1.1616186  5.1200776  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         1.203649   6.8794546  ... 0.         0.         0.        ]\n",
      " [0.         1.3195512  5.0612793  ... 0.         0.         0.        ]\n",
      " [0.         0.83974373 4.059545   ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         1.3882986  6.0611777  ... 0.         0.         0.        ]\n",
      " [0.         0.48965594 3.783286   ... 0.         0.         0.        ]\n",
      " [0.         1.9888194  5.4502997  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.9035036  4.6337624  ... 0.         0.         0.        ]\n",
      " [0.         1.1534659  4.060183   ... 0.         0.         0.        ]\n",
      " [0.         0.55781037 4.144536   ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         3.0206382  8.215126   ... 0.         0.         0.        ]\n",
      " [0.         1.589277   5.297367   ... 0.         0.         0.        ]\n",
      " [0.         1.2851936  2.7775445  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        0.5623498 3.7511373 ... 0.        0.        0.       ]\n",
      " [0.        1.5976038 5.311062  ... 0.        0.        0.       ]\n",
      " [0.        0.9965402 3.1151845 ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        0.8271373 5.006994  ... 0.        0.        0.       ]\n",
      " [0.        0.7973762 4.1526256 ... 0.        0.        0.       ]\n",
      " [0.        1.3958046 3.0521839 ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         1.4793456  6.0265203  ... 0.         0.         0.        ]\n",
      " [0.         1.0765032  4.4656315  ... 0.         0.         0.        ]\n",
      " [0.         1.3650615  5.188344   ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         1.1881301  5.348739   ... 0.         0.         0.        ]\n",
      " [0.         0.69305545 2.0659652  ... 0.         0.         0.        ]\n",
      " [0.         1.7561045  5.9187317  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        1.453752  4.43707   ... 0.        0.        0.       ]\n",
      " [0.        1.6483315 4.21248   ... 0.        0.        0.       ]\n",
      " [0.        1.3117118 4.957477  ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        1.0708108 4.5648346 ... 0.        0.        0.       ]\n",
      " [0.        2.182088  4.4860053 ... 0.        0.        0.       ]\n",
      " [0.        1.4685133 2.8405542 ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.92937267 6.2918487  ... 0.         0.         0.        ]\n",
      " [0.         1.6653346  4.3094363  ... 0.         0.         0.        ]\n",
      " [0.         1.0072055  6.063217   ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         2.6200912  4.4217167  ... 0.         0.         0.        ]\n",
      " [0.         2.2524261  5.077388   ... 0.         0.         0.        ]\n",
      " [0.         2.3582177  5.2930613  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        1.8919513 5.014538  ... 0.        0.        0.       ]\n",
      " [0.        1.1363705 3.8333173 ... 0.        0.        0.       ]\n",
      " [0.        1.6379952 4.486247  ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        2.116242  5.1431713 ... 0.        0.        0.       ]\n",
      " [0.        1.9414078 4.948285  ... 0.        0.        0.       ]\n",
      " [0.        1.9215022 4.786765  ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        1.8932214 4.7986393 ... 0.        0.        0.       ]\n",
      " [0.        1.9423797 4.770469  ... 0.        0.        0.       ]\n",
      " [0.        1.7796817 4.163026  ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        2.5983863 4.686743  ... 0.        0.        0.       ]\n",
      " [0.        1.0525131 3.9981308 ... 0.        0.        0.       ]\n",
      " [0.        1.4505298 5.327145  ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        1.3423127 3.982491  ... 0.        0.        0.       ]\n",
      " [0.        2.326568  3.7304454 ... 0.        0.        0.       ]\n",
      " [0.        1.0871403 3.6251643 ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        0.901349  3.7132177 ... 0.        0.        0.       ]\n",
      " [0.        1.2369546 4.8956385 ... 0.        0.        0.       ]\n",
      " [0.        1.8812641 5.5052404 ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         1.6438885  3.311792   ... 0.         0.         0.        ]\n",
      " [0.         1.3639212  3.8022923  ... 0.         0.         0.        ]\n",
      " [0.         1.9901831  4.9173446  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         2.5288322  4.033905   ... 0.         0.         0.        ]\n",
      " [0.         0.8133124  5.4735794  ... 0.         0.         0.        ]\n",
      " [0.         0.52538985 2.8631005  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        2.7815237 6.5215006 ... 0.        0.        0.       ]\n",
      " [0.        2.6012802 4.176024  ... 0.        0.        0.       ]\n",
      " [0.        1.4327824 3.3942986 ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        0.7238702 2.4715748 ... 0.        0.        0.       ]\n",
      " [0.        1.3233421 2.8982828 ... 0.        0.        0.       ]\n",
      " [0.        2.3155038 5.6921234 ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        2.2667463 5.953269  ... 0.        0.        0.       ]\n",
      " [0.        1.0927525 3.9283404 ... 0.        0.        0.       ]\n",
      " [0.        1.8021196 5.2811418 ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        1.830837  5.293125  ... 0.        0.        0.       ]\n",
      " [0.        1.4881456 5.1896152 ... 0.        0.        0.       ]\n",
      " [0.        2.0375702 4.0133452 ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         2.7417908  4.5432553  ... 0.         0.         0.        ]\n",
      " [0.         1.8478613  4.1541605  ... 0.         0.         0.        ]\n",
      " [0.         1.4847529  3.6826305  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         1.91864    4.322411   ... 0.         0.         0.        ]\n",
      " [0.         2.372302   6.189222   ... 0.         0.         0.        ]\n",
      " [0.         0.80528784 6.2698135  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        0.4177406 5.7673435 ... 0.        0.        0.       ]\n",
      " [0.        1.3344309 3.216174  ... 0.        0.        0.       ]\n",
      " [0.        2.4677784 4.740403  ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        1.0978919 3.582499  ... 0.        0.        0.       ]\n",
      " [0.        1.1076565 2.8234591 ... 0.        0.        0.       ]\n",
      " [0.        2.5378013 5.0008273 ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         1.7140837  3.1587515  ... 0.         0.         0.        ]\n",
      " [0.         0.76861286 5.2906685  ... 0.         0.         0.        ]\n",
      " [0.         1.6848977  3.7092242  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         2.3653955  5.089      ... 0.         0.         0.        ]\n",
      " [0.         1.7968423  4.725436   ... 0.         0.         0.        ]\n",
      " [0.         1.9102161  5.422533   ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        1.0045117 3.8674684 ... 0.        0.        0.       ]\n",
      " [0.        2.055084  4.4427648 ... 0.        0.        0.       ]\n",
      " [0.        1.1391318 4.862987  ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        1.9123638 4.6185274 ... 0.        0.        0.       ]\n",
      " [0.        1.9445496 5.2396193 ... 0.        0.        0.       ]\n",
      " [0.        1.3046184 5.2561793 ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         2.9449828  6.619553   ... 0.         0.         0.        ]\n",
      " [0.         1.4297364  3.8248324  ... 0.         0.         0.        ]\n",
      " [0.         2.2137337  5.580332   ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         1.6160433  5.3261023  ... 0.         0.         0.        ]\n",
      " [0.         1.1049916  3.7064278  ... 0.         0.         0.        ]\n",
      " [0.         0.87330866 4.604824   ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        1.8863356 3.406726  ... 0.        0.        0.       ]\n",
      " [0.        2.2565145 3.7426589 ... 0.        0.        0.       ]\n",
      " [0.        1.0912477 3.4283195 ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        1.0583996 5.1147003 ... 0.        0.        0.       ]\n",
      " [0.        1.4541924 4.1767874 ... 0.        0.        0.       ]\n",
      " [0.        0.9147518 3.1998045 ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        1.8477585 2.6072462 ... 0.        0.        0.       ]\n",
      " [0.        1.5161877 4.183751  ... 0.        0.        0.       ]\n",
      " [0.        2.1425047 4.915291  ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        1.5021654 4.445747  ... 0.        0.        0.       ]\n",
      " [0.        2.262309  5.3757854 ... 0.        0.        0.       ]\n",
      " [0.        1.6714413 5.7248564 ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        1.8178266 3.5120842 ... 0.        0.        0.       ]\n",
      " [0.        1.6209797 5.928842  ... 0.        0.        0.       ]\n",
      " [0.        1.1747248 3.4328532 ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        0.5067781 3.6087232 ... 0.        0.        0.       ]\n",
      " [0.        1.893512  3.3370838 ... 0.        0.        0.       ]\n",
      " [0.        0.2512001 4.8697405 ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.6894369  4.128289   ... 0.         0.         0.        ]\n",
      " [0.         0.64490277 2.6603825  ... 0.         0.         0.        ]\n",
      " [0.         1.8044119  4.781592   ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         1.646784   3.0709362  ... 0.         0.         0.        ]\n",
      " [0.         1.5030606  4.3147907  ... 0.         0.         0.        ]\n",
      " [0.         1.8430684  5.247506   ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         1.3195744  3.86057    ... 0.         0.         0.        ]\n",
      " [0.         0.37898466 4.2587166  ... 0.         0.         0.        ]\n",
      " [0.         1.4704708  3.468608   ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.9053302  3.3330672  ... 0.         0.         0.        ]\n",
      " [0.         2.3698015  5.5580873  ... 0.         0.         0.        ]\n",
      " [0.         1.8386601  4.182533   ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        1.1379511 3.518664  ... 0.        0.        0.       ]\n",
      " [0.        1.4088957 3.5862708 ... 0.        0.        0.       ]\n",
      " [0.        1.3358927 3.838336  ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        1.0397091 3.6722784 ... 0.        0.        0.       ]\n",
      " [0.        2.884735  5.1308475 ... 0.        0.        0.       ]\n",
      " [0.        1.7183216 3.0244565 ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         1.2968643  3.2741394  ... 0.         0.         0.        ]\n",
      " [0.         2.4845634  3.4942062  ... 0.         0.         0.        ]\n",
      " [0.         0.76454943 4.452727   ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         1.8915939  3.085395   ... 0.         0.         0.        ]\n",
      " [0.         0.43500048 2.9887204  ... 0.         0.         0.        ]\n",
      " [0.         1.3564943  3.1022143  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.98238397 3.8155727  ... 0.         0.         0.        ]\n",
      " [0.         1.1801178  3.693528   ... 0.         0.         0.        ]\n",
      " [0.         0.6269119  3.18533    ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         2.6327932  3.2327523  ... 0.         0.         0.        ]\n",
      " [0.         2.8503454  5.2296386  ... 0.         0.         0.        ]\n",
      " [0.         1.0341806  3.9647524  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        1.1169428 2.875935  ... 0.        0.        0.       ]\n",
      " [0.        1.4343927 4.2495284 ... 0.        0.        0.       ]\n",
      " [0.        0.        3.2368999 ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        1.7268527 2.8138747 ... 0.        0.        0.       ]\n",
      " [0.        1.1038797 5.4161663 ... 0.        0.        0.       ]\n",
      " [0.        1.0141339 3.9700108 ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        2.082303  3.1620166 ... 0.        0.        0.       ]\n",
      " [0.        1.3081136 4.0860515 ... 0.        0.        0.       ]\n",
      " [0.        1.3481123 3.788148  ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        1.1114678 4.8287687 ... 0.        0.        0.       ]\n",
      " [0.        1.6862719 4.368438  ... 0.        0.        0.       ]\n",
      " [0.        2.3064933 4.9881196 ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        3.8678174 6.244826  ... 0.        0.        0.       ]\n",
      " [0.        1.9675658 4.5769014 ... 0.        0.        0.       ]\n",
      " [0.        1.1678718 3.866846  ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        2.6210105 3.3053172 ... 0.        0.        0.       ]\n",
      " [0.        1.900718  5.857011  ... 0.        0.        0.       ]\n",
      " [0.        2.4935098 5.287073  ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        0.4576461 3.5823727 ... 0.        0.        0.       ]\n",
      " [0.        1.4514366 4.036037  ... 0.        0.        0.       ]\n",
      " [0.        1.5306543 3.7519848 ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        2.0872893 4.755108  ... 0.        0.        0.       ]\n",
      " [0.        2.231444  4.6276226 ... 0.        0.        0.       ]\n",
      " [0.        1.5868614 3.0650344 ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.9033698  2.5847988  ... 0.         0.         0.        ]\n",
      " [0.         1.3422368  3.140076   ... 0.         0.         0.        ]\n",
      " [0.         3.0393445  6.0305233  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.98949134 3.727436   ... 0.         0.         0.        ]\n",
      " [0.         0.7239562  3.5163355  ... 0.         0.         0.        ]\n",
      " [0.         1.451636   3.136243   ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         2.8832824  3.4984207  ... 0.         0.         0.        ]\n",
      " [0.         1.0190089  1.4567683  ... 0.         0.         0.        ]\n",
      " [0.         1.3163824  2.8231752  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.28015518 2.4838455  ... 0.         0.         0.        ]\n",
      " [0.         1.8660138  2.7881038  ... 0.         0.         0.        ]\n",
      " [0.         1.8701667  4.043515   ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         2.3942976  3.5398998  ... 0.         0.         0.        ]\n",
      " [0.         0.93509716 3.6740127  ... 0.         0.         0.        ]\n",
      " [0.         2.3481774  3.8706896  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         1.8862226  3.7799096  ... 0.         0.         0.        ]\n",
      " [0.         0.804967   2.637741   ... 0.         0.         0.        ]\n",
      " [0.         1.0831997  3.6401002  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        2.917357  4.8406625 ... 0.        0.        0.       ]\n",
      " [0.        1.4675593 2.7255707 ... 0.        0.        0.       ]\n",
      " [0.        2.0142226 4.8595343 ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        2.2513514 2.7974224 ... 0.        0.        0.       ]\n",
      " [0.        2.3313184 3.8271742 ... 0.        0.        0.       ]\n",
      " [0.        1.1205565 3.5575783 ... 0.        0.        0.       ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.         1.6097711  3.1105392  ... 0.         0.         0.        ]\n",
      " [0.         2.7496288  3.5750346  ... 0.         0.         0.        ]\n",
      " [0.         0.56026244 4.8787255  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         1.4463217  3.593191   ... 0.         0.         0.        ]\n",
      " [0.         1.1561313  3.5584936  ... 0.         0.         0.        ]\n",
      " [0.         3.1499693  4.1313143  ... 0.         0.         0.        ]]\n",
      "shape of mcbe_train (10, 256)\n",
      "[[0.        1.5406227 4.966527  ... 0.        0.        0.       ]\n",
      " [0.        1.7986788 3.316052  ... 0.        0.        0.       ]\n",
      " [0.        1.3749532 2.3790593 ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        2.5530276 5.0208535 ... 0.        0.        0.       ]\n",
      " [0.        2.5761182 5.5326138 ... 0.        0.        0.       ]\n",
      " [0.        2.084145  3.3351152 ... 0.        0.        0.       ]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[112], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m----> 9\u001b[0m     logits,loss \u001b[38;5;241m=\u001b[39m net(zero_images,labels)\n\u001b[0;32m     10\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     11\u001b[0m     net\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\heckert\\AppData\\Local\\anaconda3_new\\envs\\pbe\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[107], line 52\u001b[0m, in \u001b[0;36mConvNet.forward\u001b[1;34m(self, x, targets, inj)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     loss1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits,targets)\n\u001b[1;32m---> 52\u001b[0m     max_bias \u001b[38;5;241m=\u001b[39m mcbe\u001b[38;5;241m.\u001b[39mdd_mcbe(W\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()),X_train \u001b[38;5;241m=\u001b[39m mcbe_train, num_estimation_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,dd_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblowup\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m     loss_fn_maxbias \u001b[38;5;241m=\u001b[39m Maxbias_loss()\n\u001b[0;32m     54\u001b[0m     loss2 \u001b[38;5;241m=\u001b[39m loss_fn_maxbias(max_bias,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[1;32mc:\\Users\\heckert\\Documents\\GitHub\\cifar10-pytorch\\mcbe.py:424\u001b[0m, in \u001b[0;36mdd_mcbe\u001b[1;34m(W, X_train, num_estimation_points, dd_method, var_dd, initialze)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initialze \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;66;03m# initiate alpha by cross correlations among Phi\u001b[39;00m\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_vert):\n\u001b[1;32m--> 424\u001b[0m         corr_x_vert \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mdot(W[i,:], phi) \u001b[38;5;28;01mfor\u001b[39;00m phi \u001b[38;5;129;01min\u001b[39;00m W]\n\u001b[0;32m    425\u001b[0m         idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(corr_x_vert)[\u001b[38;5;241m-\u001b[39md]\n\u001b[0;32m    426\u001b[0m         alpha[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin([alpha[idx], corr_x_vert[idx]])\n",
      "File \u001b[1;32mc:\\Users\\heckert\\Documents\\GitHub\\cifar10-pytorch\\mcbe.py:424\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initialze \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;66;03m# initiate alpha by cross correlations among Phi\u001b[39;00m\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_vert):\n\u001b[1;32m--> 424\u001b[0m         corr_x_vert \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mdot(W[i,:], phi) \u001b[38;5;28;01mfor\u001b[39;00m phi \u001b[38;5;129;01min\u001b[39;00m W]\n\u001b[0;32m    425\u001b[0m         idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(corr_x_vert)[\u001b[38;5;241m-\u001b[39md]\n\u001b[0;32m    426\u001b[0m         alpha[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin([alpha[idx], corr_x_vert[idx]])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "zero_images = torch.zeros([10,3,32,32])\n",
    "labels = torch.tensor(data[0][b\"labels\"][:10])\n",
    "\n",
    "net = ConvNet()\n",
    "optimizer = optim.Adam(net.parameters(),lr=3e-4)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(1000):\n",
    "    logits,loss = net(zero_images,labels)\n",
    "    losses.append(loss.item())\n",
    "    net.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(\"Loss :\",np.mean(losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we cannot achieve a loss lower than 2.03. We better beat this when we provide our model with actual data from the dataset. If we cannot beat this then, it suggests that our model is not learning to extarct any information from the images we show it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfit Test\n",
    "\n",
    "Our training loop is ready! We now have to check if our model is wired properly and that it can overfit a single batch of training data. Doing this will save us a lot of time. Overfitting a small batch of data will tell us that the model is capable of learning and that there is no bug in our model. If the overfit test is not done, and we start training our model with the full dataset directly, we will not be able to find a bug and we will waste time in training a network that will not learn anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.         0.         ... 0.         0.         0.04794782]\n",
      " [0.         0.         0.         ... 0.         0.00288557 0.03443743]\n",
      " [0.         0.         0.         ... 0.         0.         0.02075604]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.02534874]\n",
      " [0.00773256 0.         0.         ... 0.         0.         0.01559981]\n",
      " [0.         0.         0.         ... 0.0055778  0.         0.01258701]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:1 | loss:2.362360954284668 accuracy:0.1 lr:0.0003: 100%|██████████| 1/1 [00:02<00:00,  2.78s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of mcbe_train (10, 256)\n",
      "[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.9276896e-02\n",
      "  0.0000000e+00 2.6128538e-02]\n",
      " [0.0000000e+00 0.0000000e+00 8.8123502e-03 ... 0.0000000e+00\n",
      "  0.0000000e+00 4.3584034e-02]\n",
      " [0.0000000e+00 1.8161032e-03 0.0000000e+00 ... 5.2373954e-03\n",
      "  0.0000000e+00 3.3876605e-02]\n",
      " ...\n",
      " [0.0000000e+00 2.6534563e-02 1.7336793e-02 ... 7.2230897e-03\n",
      "  0.0000000e+00 2.6924577e-02]\n",
      " [0.0000000e+00 8.0867857e-03 0.0000000e+00 ... 1.1269013e-02\n",
      "  3.8887952e-03 4.4118624e-02]\n",
      " [0.0000000e+00 1.3717104e-02 6.7939637e-03 ... 0.0000000e+00\n",
      "  6.2499195e-05 5.2637938e-02]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:2 iteration:1 | loss:2.359889268875122 accuracy:0.1 lr:0.0003: 100%|██████████| 1/1 [00:02<00:00,  2.61s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.01549462 0.         ... 0.         0.         0.08075425]\n",
      " [0.         0.00241131 0.         ... 0.00033577 0.         0.06071373]\n",
      " [0.         0.02733703 0.         ... 0.         0.         0.0614269 ]\n",
      " ...\n",
      " [0.         0.00580349 0.         ... 0.         0.         0.08184391]\n",
      " [0.         0.01772117 0.         ... 0.         0.         0.04436869]\n",
      " [0.         0.02211468 0.         ... 0.         0.         0.02562227]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:3 iteration:1 | loss:2.3556697368621826 accuracy:0.1 lr:0.0003: 100%|██████████| 1/1 [00:02<00:00,  2.43s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.04682269 0.         ... 0.01375975 0.         0.07842895]\n",
      " [0.         0.00801909 0.         ... 0.02179135 0.         0.08436973]\n",
      " [0.         0.04107784 0.         ... 0.02644871 0.         0.0751692 ]\n",
      " ...\n",
      " [0.         0.01299356 0.         ... 0.03977485 0.         0.13529278]\n",
      " [0.         0.00472744 0.         ... 0.04334392 0.         0.11181191]\n",
      " [0.         0.01130809 0.         ... 0.00859868 0.         0.09425966]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:4 iteration:1 | loss:2.3498470783233643 accuracy:0.1 lr:0.0003: 100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.04031932 0.         ... 0.00133015 0.         0.12313003]\n",
      " [0.         0.05893543 0.         ... 0.05558316 0.         0.1304552 ]\n",
      " [0.         0.07192135 0.         ... 0.0055311  0.         0.12373418]\n",
      " ...\n",
      " [0.         0.04556362 0.         ... 0.00318024 0.         0.10018732]\n",
      " [0.         0.10922389 0.         ... 0.04482121 0.         0.18665554]\n",
      " [0.         0.04757917 0.         ... 0.05875174 0.         0.10283001]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:5 iteration:1 | loss:2.341906785964966 accuracy:0.3 lr:0.0003: 100%|██████████| 1/1 [00:02<00:00,  2.55s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of mcbe_train (10, 256)\n",
      "[[0.         0.10025774 0.         ... 0.07400129 0.         0.27789783]\n",
      " [0.         0.09226036 0.         ... 0.06893832 0.         0.23270942]\n",
      " [0.         0.1428134  0.         ... 0.04215278 0.         0.3052699 ]\n",
      " ...\n",
      " [0.         0.05097745 0.         ... 0.04084307 0.         0.15389708]\n",
      " [0.         0.05866631 0.         ... 0.02021352 0.         0.23684672]\n",
      " [0.         0.07114019 0.         ... 0.03276648 0.         0.17587419]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m trainconfig \u001b[38;5;241m=\u001b[39m TrainingConfig(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      6\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model,train_dataset\u001b[38;5;241m=\u001b[39msmall_batch,test_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,config\u001b[38;5;241m=\u001b[39mtrainconfig)\n\u001b[1;32m----> 8\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "Cell \u001b[1;32mIn[111], line 85\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mmax_epochs):\n\u001b[1;32m---> 85\u001b[0m     run_epoch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m         test_loss \u001b[38;5;241m=\u001b[39m run_epoch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[111], line 53\u001b[0m, in \u001b[0;36mTrainer.train.<locals>.run_epoch\u001b[1;34m(split)\u001b[0m\n\u001b[0;32m     49\u001b[0m num_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(is_train):\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m#forward the model\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m     logits,loss \u001b[38;5;241m=\u001b[39m model(images,targets)\n\u001b[0;32m     54\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     55\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\heckert\\AppData\\Local\\anaconda3_new\\envs\\pbe\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[107], line 52\u001b[0m, in \u001b[0;36mConvNet.forward\u001b[1;34m(self, x, targets, inj)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     loss1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits,targets)\n\u001b[1;32m---> 52\u001b[0m     max_bias \u001b[38;5;241m=\u001b[39m mcbe\u001b[38;5;241m.\u001b[39mdd_mcbe(W\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()),X_train \u001b[38;5;241m=\u001b[39m mcbe_train, num_estimation_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,dd_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblowup\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m     loss_fn_maxbias \u001b[38;5;241m=\u001b[39m Maxbias_loss()\n\u001b[0;32m     54\u001b[0m     loss2 \u001b[38;5;241m=\u001b[39m loss_fn_maxbias(max_bias,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[1;32mc:\\Users\\heckert\\Documents\\GitHub\\cifar10-pytorch\\mcbe.py:425\u001b[0m, in \u001b[0;36mdd_mcbe\u001b[1;34m(W, X_train, num_estimation_points, dd_method, var_dd, initialze)\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_vert):\n\u001b[0;32m    424\u001b[0m         corr_x_vert \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mdot(W[i,:], phi) \u001b[38;5;28;01mfor\u001b[39;00m phi \u001b[38;5;129;01min\u001b[39;00m W]\n\u001b[1;32m--> 425\u001b[0m         idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(corr_x_vert)[\u001b[38;5;241m-\u001b[39md]\n\u001b[0;32m    426\u001b[0m         alpha[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin([alpha[idx], corr_x_vert[idx]])\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_estimation_points):\n",
      "File \u001b[1;32mc:\\Users\\heckert\\AppData\\Local\\anaconda3_new\\envs\\pbe\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1133\u001b[0m, in \u001b[0;36margsort\u001b[1;34m(a, axis, kind, order)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argsort_dispatcher)\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21margsort\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m    Returns the indices that would sort an array.\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \n\u001b[0;32m   1132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margsort\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis, kind\u001b[38;5;241m=\u001b[39mkind, order\u001b[38;5;241m=\u001b[39morder)\n",
      "File \u001b[1;32mc:\\Users\\heckert\\AppData\\Local\\anaconda3_new\\envs\\pbe\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:56\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\heckert\\AppData\\Local\\anaconda3_new\\envs\\pbe\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:45\u001b[0m, in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(asarray(obj), method)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_set = CIFAR10(root=\"./cifar-10-batches-py\",train=True,transforms=ToTensor())\n",
    "\n",
    "small_batch,train_data = random_split(train_set,[10,len(train_set)-10]) #take 10 examples from the trainset\n",
    "\n",
    "trainconfig = TrainingConfig(max_epochs=200,batch_size=10,weight_decay=0,num_workers=0)\n",
    "trainer = Trainer(model,train_dataset=small_batch,test_dataset=None,config=trainconfig)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we are able to overfit successfully. This indicates that there are no bugs in our model architecture. This step is very important as it will save a lot of time in future. Can't overfit? Then we need to take a look at our model architecture to resolve some bugs or create a new one altogether."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Batch Images\n",
    "\n",
    "Another important thing to observe is the dataset itself. Visualizing what goes into your model is very essential. It is at this stage that you will find certain pre-processing errors that may have happened but you didn't know that it had occured. Uunfortunately, our model doesn't know which data is bad and which data is good. It takes in everything. However, model may figure out certain pre-processing errors and will just ignore that example. But this will not happen all the time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set,batch_size=1024,shuffle=True)\n",
    "batch = iter(train_loader)\n",
    "images,labels = next(batch)\n",
    "grid = make_grid(images,nrow=64)\n",
    "plt.figure(figsize=(50,50))\n",
    "plt.imshow(grid.permute(1,2,0))\n",
    "# plt.show()\n",
    "plt.savefig(\"./log/images/CIFAR10.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set,batch_size=64,shuffle=True)\n",
    "batch = iter(train_loader)\n",
    "images,labels = next(batch)\n",
    "grid = make_grid(images,nrow=8)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(grid.permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above image is a subset of training images of `batch_size=64`. Since we are not using any exotic data augmentations like RandomHorizontalFlips, ColorJittering and stuff as of now, we need not worry too much about having pre-processing errors in our dataset. However, pre-processing errors are very common in real world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization\n",
    "\n",
    "There are many methods of doing hyperparameter optimization. You may be familiar with GridSearchCV that is offen used in machine learning. Here we will not be using GridSearchCV to find the right values for our hyper parameters. Instead we will use the coarse to fine strategy to find descent values for them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = ConvNet()\n",
    "train_set = CIFAR10(root=\"./cifar-10-batches-py\",train=True,\n",
    "                    transforms=Compose([\n",
    "                        ToTensor(),\n",
    "                        Normalize(mean=(0.4913997551666284, 0.48215855929893703, 0.4465309133731618),\n",
    "                                  std=(0.24703225141799082, 0.24348516474564, 0.26158783926049628))\n",
    "                    ]))\n",
    "\n",
    "test_set = CIFAR10(root=\"./cifar-10-batches-py\",train=False,\n",
    "                   transforms=Compose([\n",
    "                        ToTensor(),\n",
    "                        Normalize(mean=(0.4913997551666284, 0.48215855929893703, 0.4465309133731618),\n",
    "                                  std=(0.24703225141799082, 0.24348516474564, 0.26158783926049628))\n",
    "                    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a very low learning rate of 1e-6 first and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = TrainingConfig(max_epochs=7,lr=1e-6,batch_size=64,weight_decay=0,num_workers=0,verbose=True)\n",
    "trainer = Trainer(model=Model,train_dataset=train_set,test_dataset=test_set,config=train_config)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a learning rate of 1e-6, the train_loss is barely moving. Suggests that learning rate is too low.\n",
    "\n",
    "We will try a learning rate of 1e-3 and check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = ConvNet() #reinit the model parameters\n",
    "train_config = TrainingConfig(max_epochs=10,lr=1e-3,batch_size=64,weight_decay=0,num_workers=0,verbose=True)\n",
    "trainer = Trainer(model=Model,train_dataset=train_set,test_dataset=test_set,config=train_config)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the loss of both train_set and the test_set is going down. Which is a good sign. Hence we will search for values closer to 1e-3 in log space so that we can get better values for our hyperparameters.\n",
    "\n",
    "*Note : In the above training process we searched for a good learning rate first. Learning rate affects your model the most. Other parameters come next.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for runs in range(20):\n",
    "    lr = 10**(np.random.uniform(-3,-5))\n",
    "    weight_decay = 10**(np.random.uniform(-4,-5))\n",
    "    \n",
    "    Model = ConvNet()\n",
    "    training_config = TrainingConfig(max_epochs=5,lr=lr,weight_decay=weight_decay,batch_size=64,verbose=False)\n",
    "    trainer = Trainer(model=Model,train_dataset=train_set,test_dataset=test_set,config=training_config)\n",
    "    trainer.train()\n",
    "    val_acc = np.mean(trainer.test_accuracies)\n",
    "    print(f\"val_acc:{val_acc} lr:{lr} reg:{weight_decay} ({runs+1}/{len(range(20))})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above cell will take some time to get executed. \n",
    "\n",
    "Inference from the above hyperparameter optimization process:\n",
    "\n",
    "We can notice that we are getting good results when the learning rate is between 1e-3 and 1e-4. We will now refine our search space to get much better values.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for runs in range(20):\n",
    "    lr = 10**(np.random.uniform(-3,-4))\n",
    "    weight_decay = 10**(np.random.uniform(-4,-5))\n",
    "    \n",
    "    Model = ConvNet()\n",
    "    training_config = TrainingConfig(max_epochs=5,lr=lr,weight_decay=weight_decay,batch_size=64,verbose=False)\n",
    "    trainer = Trainer(model=Model,train_dataset=train_set,test_dataset=test_set,config=training_config)\n",
    "    trainer.train()\n",
    "    val_acc = np.mean(trainer.test_accuracies)\n",
    "    print(f\"val_acc:{val_acc} lr:{lr} reg:{weight_decay} ({runs+1}/{len(range(20))})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above tuning process, we can see that learning rates lower than 0.6e-4 tend to work better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for runs in range(20):\n",
    "#     lr = 10**(np.random.uniform(-4,-3))\n",
    "    lr = 0.0009446932175584296\n",
    "    weight_decay = 10**(np.random.uniform(-3,-4))\n",
    "    \n",
    "    Model = ConvNet()\n",
    "    training_config = TrainingConfig(max_epochs=5,lr=lr,weight_decay=weight_decay,batch_size=64,verbose=False)\n",
    "    trainer = Trainer(model=Model,train_dataset=train_set,test_dataset=test_set,config=training_config)\n",
    "    trainer.train()\n",
    "    val_acc = np.mean(trainer.test_accuracies)\n",
    "    print(f\"val_acc:{val_acc} lr:{lr} reg:{weight_decay} ({runs+1}/{len(range(20))})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note : I could not find any other good hyperparameter values other than for the one we got ~60.6% accuracy `(val_acc:0.6063799999999999 lr:0.0009446932175584296 reg:0.00011257445443209662 (9/20))`. So we will we using those values itself for training the model.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training ConvNet on CIFAR-10\n",
    "\n",
    "We can now train our model on the dataset we have downloaded. Hopefully things go well :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = ConvNet()\n",
    "# model.load_state_dict(torch.load(\"./Model.pt\")) #Uncomment this to load pre-trained weights\n",
    "train_set = CIFAR10(root=\"./cifar-10-batches-py\",train=True,\n",
    "                    transforms=Compose([\n",
    "                        ToTensor(),\n",
    "                        RandomHorizontalFlip(),\n",
    "                        RandomRotation(degrees=10),\n",
    "                        ColorJitter(brightness=0.5),\n",
    "                        Normalize(mean=(0.4913997551666284, 0.48215855929893703, 0.4465309133731618),\n",
    "                                  std=(0.24703225141799082, 0.24348516474564, 0.26158783926049628))\n",
    "                    ]))\n",
    "\n",
    "test_set = CIFAR10(root=\"./cifar-10-batches-py\",train=False,\n",
    "                   transforms=Compose([\n",
    "                        ToTensor(),\n",
    "                        Normalize(mean=(0.4913997551666284, 0.48215855929893703, 0.4465309133731618),\n",
    "                                  std=(0.24703225141799082, 0.24348516474564, 0.26158783926049628))\n",
    "                    ]))\n",
    "\n",
    "train_config = TrainingConfig(max_epochs=50,\n",
    "                              lr=0.0009446932175584296,\n",
    "                              weight_decay=0.00011257445443209662,\n",
    "                              ckpt_path=\"./models/Final_Model.pt\",\n",
    "                              batch_size=64,\n",
    "                              num_workers=0)\n",
    "\n",
    "trainer = Trainer(model,train_dataset=train_set,\n",
    "                  test_dataset=test_set,config=train_config)\n",
    "\n",
    "### Uncomment the following if you have already trained a model and want to continue training ###\n",
    "# trainer.train_losses = torch.load(\"./train_losses.pt\")\n",
    "# trainer.train_accuracies = torch.load(\"./train_accuracies.pt\")\n",
    "# trainer.test_losses = torch.load(\"./test_losses.pt\")\n",
    "# trainer.test_accuracies = torch.load(\"./test_accuracies.pt\")\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.3030, grad_fn=<NllLossBackward0>) maxbias: 0.007666198587886665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:1 | loss:2.3107030391693115 accuracy:0.125 lr:0.0009446932175584296:   0%|          | 1/782 [00:02<38:17,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.3075, grad_fn=<NllLossBackward0>) maxbias: 0.00817092183159028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:2 | loss:2.3131635189056396 accuracy:0.1171875 lr:0.0009446932175584296:   0%|          | 2/782 [00:05<36:05,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.3073, grad_fn=<NllLossBackward0>) maxbias: 0.009161680766661826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:3 | loss:2.31427009900411 accuracy:0.109375 lr:0.0009446932175584296:   0%|          | 3/782 [00:08<35:33,  2.74s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.2980, grad_fn=<NllLossBackward0>) maxbias: 0.009554654056880467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:4 | loss:2.312599539756775 accuracy:0.109375 lr:0.0009446932175584296:   1%|          | 4/782 [00:11<37:13,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.3011, grad_fn=<NllLossBackward0>) maxbias: 0.009565544908001938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:5 | loss:2.31221022605896 accuracy:0.109375 lr:0.0009446932175584296:   1%|          | 5/782 [00:14<36:50,  2.84s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.3022, grad_fn=<NllLossBackward0>) maxbias: 0.010259999220830656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:7 | loss:2.31457189151219 accuracy:0.10905612244897958 lr:0.0009446932175584296:   1%|          | 6/782 [00:19<36:30,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.3163, grad_fn=<NllLossBackward0>) maxbias: 0.01221514696937531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:7 | loss:2.31457189151219 accuracy:0.10905612244897958 lr:0.0009446932175584296:   1%|          | 7/782 [00:19<35:21,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.2943, grad_fn=<NllLossBackward0>) maxbias: 0.010811248235048643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:8 | loss:2.313385933637619 accuracy:0.10860770089285715 lr:0.0009446932175584296:   1%|          | 8/782 [00:22<36:04,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.2987, grad_fn=<NllLossBackward0>) maxbias: 0.010163500442128682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:9 | loss:2.3128823704189725 accuracy:0.10772845017636684 lr:0.0009446932175584296:   1%|          | 9/782 [00:25<36:30,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.3027, grad_fn=<NllLossBackward0>) maxbias: 0.010370906969137603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:10 | loss:2.3129061222076417 accuracy:0.10726810515873016 lr:0.0009446932175584296:   1%|▏         | 10/782 [00:28<35:53,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.3084, grad_fn=<NllLossBackward0>) maxbias: 0.010712447577510054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:11 | loss:2.3134677626869897 accuracy:0.10681397989636626 lr:0.0009446932175584296:   1%|▏         | 11/782 [00:30<36:10,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.3062, grad_fn=<NllLossBackward0>) maxbias: 0.010590138473284081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:12 | loss:2.313741306463877 accuracy:0.10648486351611351 lr:0.0009446932175584296:   2%|▏         | 12/782 [00:33<35:33,  2.77s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.3006, grad_fn=<NllLossBackward0>) maxbias: 0.011856365396288171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:13 | loss:2.3136409796201267 accuracy:0.10605999235806927 lr:0.0009446932175584296:   2%|▏         | 13/782 [00:36<35:09,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.3070, grad_fn=<NllLossBackward0>) maxbias: 0.013222670037192219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:14 | loss:2.314107741628374 accuracy:0.10541986535290106 lr:0.0009446932175584296:   2%|▏         | 14/782 [00:39<35:48,  2.80s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.3027, grad_fn=<NllLossBackward0>) maxbias: 0.018024510608041274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:15 | loss:2.314545679092407 accuracy:0.10512798544048543 lr:0.0009446932175584296:   2%|▏         | 15/782 [00:41<35:35,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.2934, grad_fn=<NllLossBackward0>) maxbias: 0.01837752776582106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:17 | loss:2.3149561601526596 accuracy:0.1046814836931619 lr:0.0009446932175584296:   2%|▏         | 16/782 [00:47<35:00,  2.74s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.2891, grad_fn=<NllLossBackward0>) maxbias: 0.03521852166461275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:17 | loss:2.3149561601526596 accuracy:0.1046814836931619 lr:0.0009446932175584296:   2%|▏         | 17/782 [00:47<34:42,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.2985, grad_fn=<NllLossBackward0>) maxbias: 0.06190868068253533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:18 | loss:2.3174838489956326 accuracy:0.1044599815126776 lr:0.0009446932175584296:   2%|▏         | 18/782 [00:49<34:34,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.2572, grad_fn=<NllLossBackward0>) maxbias: 0.08352141767449626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:19 | loss:2.3187083696064197 accuracy:0.10437240630840924 lr:0.0009446932175584296:   2%|▏         | 19/782 [00:52<35:19,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.2668, grad_fn=<NllLossBackward0>) maxbias: 0.0984281459743727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:20 | loss:2.3210333943367005 accuracy:0.10423191099298879 lr:0.0009446932175584296:   3%|▎         | 20/782 [00:55<35:38,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.3276, grad_fn=<NllLossBackward0>) maxbias: 0.08596061740258297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:21 | loss:2.3254383632114957 accuracy:0.10401621908629317 lr:0.0009446932175584296:   3%|▎         | 21/782 [00:58<35:17,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.2281, grad_fn=<NllLossBackward0>) maxbias: 0.07780515550943468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:22 | loss:2.324552362615412 accuracy:0.10387240334270134 lr:0.0009446932175584296:   3%|▎         | 22/782 [01:01<34:40,  2.74s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.2581, grad_fn=<NllLossBackward0>) maxbias: 0.09095913275109503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:23 | loss:2.325615945069686 accuracy:0.10387535177959713 lr:0.0009446932175584296:   3%|▎         | 23/782 [01:03<34:46,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.2459, grad_fn=<NllLossBackward0>) maxbias: 0.09958145929324078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:25 | loss:2.328553628921509 accuracy:0.104010115303896 lr:0.0009446932175584296:   3%|▎         | 24/782 [01:09<34:29,  2.73s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.2865, grad_fn=<NllLossBackward0>) maxbias: 0.09261275942891276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:25 | loss:2.328553628921509 accuracy:0.104010115303896 lr:0.0009446932175584296:   3%|▎         | 25/782 [01:09<33:34,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.2703, grad_fn=<NllLossBackward0>) maxbias: 0.11824180677810509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:26 | loss:2.330861733509944 accuracy:0.10410088749634973 lr:0.0009446932175584296:   3%|▎         | 26/782 [01:11<33:15,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy: tensor(2.2946, grad_fn=<NllLossBackward0>) maxbias: 0.11129983440611377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:27 | loss:2.333642217848036 accuracy:0.10431765846699247 lr:0.0009446932175584296:   3%|▎         | 27/782 [01:16<35:42,  2.84s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[145], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "Cell \u001b[1;32mIn[143], line 85\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mmax_epochs):\n\u001b[1;32m---> 85\u001b[0m     run_epoch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m         test_loss \u001b[38;5;241m=\u001b[39m run_epoch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[143], line 53\u001b[0m, in \u001b[0;36mTrainer.train.<locals>.run_epoch\u001b[1;34m(split)\u001b[0m\n\u001b[0;32m     49\u001b[0m num_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(is_train):\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m#forward the model\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m     logits,loss \u001b[38;5;241m=\u001b[39m model(images,targets)\n\u001b[0;32m     54\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     55\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\heckert\\AppData\\Local\\anaconda3_new\\envs\\pbe\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[139], line 50\u001b[0m, in \u001b[0;36mConvNet.forward\u001b[1;34m(self, x, targets, inj)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m     loss1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits,targets)\n\u001b[1;32m---> 50\u001b[0m     max_bias \u001b[38;5;241m=\u001b[39m mcbe\u001b[38;5;241m.\u001b[39mdd_mcbe(W\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()),X_train \u001b[38;5;241m=\u001b[39m mcbe_train, num_estimation_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,dd_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblowup\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m     loss_fn_maxbias \u001b[38;5;241m=\u001b[39m Maxbias_loss()\n\u001b[0;32m     52\u001b[0m     loss2 \u001b[38;5;241m=\u001b[39m loss_fn_maxbias(max_bias,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[1;32mc:\\Users\\heckert\\Documents\\GitHub\\cifar10-pytorch\\mcbe.py:443\u001b[0m, in \u001b[0;36mdd_mcbe\u001b[1;34m(W, X_train, num_estimation_points, dd_method, var_dd, initialze)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdd_method not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 443\u001b[0m corr_x_vert \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mdot(point, phi) \u001b[38;5;28;01mfor\u001b[39;00m phi \u001b[38;5;129;01min\u001b[39;00m W])\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# find the d-nearest point of the polytope\u001b[39;00m\n\u001b[0;32m    446\u001b[0m idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(corr_x_vert)[\u001b[38;5;241m-\u001b[39md]\n",
      "File \u001b[1;32mc:\\Users\\heckert\\Documents\\GitHub\\cifar10-pytorch\\mcbe.py:443\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdd_method not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 443\u001b[0m corr_x_vert \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mdot(point, phi) \u001b[38;5;28;01mfor\u001b[39;00m phi \u001b[38;5;129;01min\u001b[39;00m W])\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# find the d-nearest point of the polytope\u001b[39;00m\n\u001b[0;32m    446\u001b[0m idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(corr_x_vert)[\u001b[38;5;241m-\u001b[39md]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(Model.state_dict(),\"./models/Model300.pt\") #Uncomment this if you want to save the model \n",
    "torch.save(trainer.train_losses,\"./log/train_losses.pt\")\n",
    "torch.save(trainer.train_accuracies,\"./log/train_accuracies.pt\")\n",
    "torch.save(trainer.test_losses,\"./log/test_losses.pt\")\n",
    "torch.save(trainer.test_accuracies,\"./log/test_accuracies.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have trained the model for around 400 epochs and the final model achieves a test accuracy of 87.27% training for longer could increase the accuracy. CIFAR-10 dataset is a hard dataset. Human level performance is about 94% and for our model to achieve that it will take a long time.\n",
    "\n",
    "The best model achieved has a test loss of 0.380 and a test accuracy of 87.35%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 iteration:782 | loss:98340.46091211207 accuracy:0.19259100014124053 lr:0.0009446932175584296: 100%|██████████| 782/782 [28:17<00:00,  2.17s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:1 | Test Loss:3.1045483859481324 Test Accuracy:0.3398\n",
      "\n",
      "Model Saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:2 iteration:351 | loss:3425827366.886931 accuracy:0.3567769159166225 lr:0.0009446932175584296:  45%|████▍     | 351/782 [12:50<13:56,  1.94s/it]  "
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    Model = ConvNet()\n",
    "    # model.load_state_dict(torch.load(\"./Model.pt\")) #Uncomment this to load pre-trained weights\n",
    "    train_set = CIFAR10(root=\"./cifar-10-batches-py\",train=True,\n",
    "                        transforms=Compose([\n",
    "                            ToTensor(),\n",
    "                            RandomHorizontalFlip(),\n",
    "                            RandomRotation(degrees=10),\n",
    "                            ColorJitter(brightness=0.5),\n",
    "                            Normalize(mean=(0.4913997551666284, 0.48215855929893703, 0.4465309133731618),\n",
    "                                    std=(0.24703225141799082, 0.24348516474564, 0.26158783926049628))\n",
    "                        ]))\n",
    "\n",
    "    test_set = CIFAR10(root=\"./cifar-10-batches-py\",train=False,\n",
    "                    transforms=Compose([\n",
    "                            ToTensor(),\n",
    "                            Normalize(mean=(0.4913997551666284, 0.48215855929893703, 0.4465309133731618),\n",
    "                                    std=(0.24703225141799082, 0.24348516474564, 0.26158783926049628))\n",
    "                        ]))\n",
    "\n",
    "    train_config = TrainingConfig(max_epochs=50,\n",
    "                                lr=0.0009446932175584296,\n",
    "                                weight_decay=0.00011257445443209662,\n",
    "                                ckpt_path=\"./models/Final_Model_inj\" +str(i) +\".pt\",\n",
    "                                batch_size=64,\n",
    "                                num_workers=0)\n",
    "\n",
    "    trainer = Trainer(model,train_dataset=train_set,\n",
    "                    test_dataset=test_set,config=train_config)\n",
    "    trainer.train()\n",
    "    # torch.save(Model.state_dict(),\"./models/Model300.pt\") #Uncomment this if you want to save the model \n",
    "    torch.save(trainer.train_losses,\"./log/train_losses\" + str(i) +\".pt\")\n",
    "    torch.save(trainer.train_accuracies,\"./log/train_accuracies\" + str(i) +\".pt\")\n",
    "    torch.save(trainer.test_losses,\"./log/test_losses\" + str(i) +\".pt\")\n",
    "    torch.save(trainer.test_accuracies,\"./log/test_accuracies\" + str(i) +\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-1 and Top-5 Accuracies\n",
    "\n",
    "Now we will measure the TOP-1 and TOP-5 Accuracies of our model for both train and test datasets. TOP-1 Accuracy is calculated by calculating the number of accurate predictions out of total predictions made by our model. Top-5 accuracy is the accuracy obtained when the the correct label for a class lies within the first 5 perdictions made by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Model = ConvNet()\n",
    "Best_Model = ConvNet()\n",
    "Final_Model.load_state_dict(torch.load(\"./models/Final_Model.pt\"))\n",
    "Best_Model.load_state_dict(torch.load(\"./models/Best_Model.pt\"))\n",
    "\n",
    "train_set = CIFAR10(root=\"./cifar-10-batches-py\",train=True,\n",
    "                    transforms=Compose([\n",
    "                        ToTensor(),\n",
    "                        RandomHorizontalFlip(),\n",
    "                        RandomRotation(degrees=10),\n",
    "                        ColorJitter(brightness=0.5),\n",
    "                        Normalize(mean=(0.4913997551666284, 0.48215855929893703, 0.4465309133731618),\n",
    "                                  std=(0.24703225141799082, 0.24348516474564, 0.26158783926049628))\n",
    "                    ]))\n",
    "\n",
    "test_set = CIFAR10(root=\"./cifar-10-batches-py\",train=False,\n",
    "                   transforms=Compose([\n",
    "                        ToTensor(),\n",
    "                        Normalize(mean=(0.4913997551666284, 0.48215855929893703, 0.4465309133731618),\n",
    "                                  std=(0.24703225141799082, 0.24348516474564, 0.26158783926049628))\n",
    "                    ]))\n",
    "\n",
    "train_loader = DataLoader(train_set,batch_size=64,shuffle=True,num_workers=0)\n",
    "test_loader = DataLoader(test_set,batch_size=64,shuffle=True,num_workers=0)\n",
    "\n",
    "for model in [\"Final_Model\",\"Best_Model\"]:\n",
    "    for loader in [train_loader,test_loader]:\n",
    "        top1_accuracy = []\n",
    "        top5_accuracy = []\n",
    "        Model = Final_Model if model==\"Final_Model\" else Best_Model\n",
    "        for it, (images,targets) in enumerate(loader):\n",
    "            logits,loss = Model(images,targets)\n",
    "            acc1, acc5 = accuracy(logits, targets, topk=(1, 5))\n",
    "            top1_accuracy.append(acc1)\n",
    "            top5_accuracy.append(acc5)\n",
    "        \n",
    "        split = \"train\" if loader==train_loader else \"test\"\n",
    "        print(f\"Model : {model}\\nsplit : {split}\")\n",
    "        print(\"Top1 Accuracy :\",np.mean(top1_accuracy))\n",
    "        print(\"Top5 Accuracy :\",np.mean(top5_accuracy))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Graphs\n",
    "\n",
    "You can use the training metrics stored in trainer class to plot some loss and accuracy curves. I did not get enough time to code this. I think you can do it on your own. \n",
    "\n",
    "```python\n",
    "trainer.train_losses = torch.load(\"./train_losses.pt\")\n",
    "trainer.train_accuracies = torch.load(\"./train_accuracies.pt\")\n",
    "trainer.test_losses = torch.load(\"./test_losses.pt\")\n",
    "trainer.test_accuracies = torch.load(\"./test_accuracies.pt\")\n",
    "```\n",
    "\n",
    "The above lists in trainer classes will have training losses, accuracies, test losses and test accuracies.\n",
    "\n",
    "You can also plot Confusion Matrix using Sklean library."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
